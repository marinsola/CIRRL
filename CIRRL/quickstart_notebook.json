{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CIRRL Quick Start Guide\n",
        "\n",
        "This notebook demonstrates how to use CIRRL for causal representation learning on single-cell data.\n",
        "\n",
        "## What is CIRRL?\n",
        "\n",
        "CIRRL combines:\n",
        "- **DPA (Distributional Principal Autoencoder)**: Learns latent representations across multiple environments\n",
        "- **DRIG (Distributionally Robust Instrumental Regression)**: Performs robust regression on learned representations\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. Load and preprocess data\n",
        "2. Train DPA model to learn causal representations\n",
        "3. Apply DRIG estimator on learned representations\n",
        "4. Evaluate performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import sys\n",
        "sys.path.append('..')  # Add parent directory to path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from cirrl import (\n",
        "    DPA, OnlyRelu,\n",
        "    load_singlecell_data,\n",
        "    train_cirrl_model,\n",
        "    est_drig_gd_auto,\n",
        "    compare_latent_dimensions\n",
        ")\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load single-cell data\n",
        "X, Y, E, X_test, Y_test, test_envs = load_singlecell_data(\n",
        "    train_path='../data/singlecell.pkl',\n",
        "    test_path='../data/singlecelltest.pkl',\n",
        "    separate_test_path='../data/testenvs_separate.pkl'\n",
        ")\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"  Training samples: {X.shape[0]}\")\n",
        "print(f\"  Features: {X.shape[1]}\")\n",
        "print(f\"  Environments: {E.shape[1]}\")\n",
        "print(f\"  Test samples: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize and Train DPA Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(123)\n",
        "np.random.seed(123)\n",
        "\n",
        "# Initialize variance regularizer\n",
        "SIGMA = OnlyRelu(epsilon=0.1)\n",
        "\n",
        "# Create DPA model\n",
        "dpa = DPA(\n",
        "    data_dim=X.shape[1],\n",
        "    latent_dims=[3],  # Latent dimension\n",
        "    num_layer=2,\n",
        "    condition_dim=E.shape[1],\n",
        "    lr=1e-4,\n",
        "    hidden_dim=400,\n",
        "    bn_enc=True,\n",
        "    bn_dec=True,\n",
        "    priorvar=SIGMA,\n",
        "    resblock=True,\n",
        "    totalvar=True,\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "print(\"DPA model initialized!\")\n",
        "print(f\"Device: {dpa.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = train_cirrl_model(\n",
        "    dpa, X, Y, E, X_test, Y_test,\n",
        "    alpha=0.1,    # GMM loss weight\n",
        "    beta=0,       # Regularization weight\n",
        "    gamma=5,      # DRIG gamma for evaluation\n",
        "    epochs=1000,\n",
        "    batch_size=len(X),  # Full batch\n",
        "    print_every=100,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Visualize Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# MSE curves\n",
        "if history['train_mse'] and history['test_mse']:\n",
        "    axes[0].plot(history['train_mse'], label='Train MSE', linewidth=2)\n",
        "    axes[0].plot(history['test_mse'], label='Test MSE', linewidth=2)\n",
        "    axes[0].set_xlabel('Evaluation Step', fontsize=12)\n",
        "    axes[0].set_ylabel('MSE', fontsize=12)\n",
        "    axes[0].set_title('Training Progress', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend(fontsize=10)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Loss components\n",
        "if history['dpa_loss']:\n",
        "    axes[1].plot(history['dpa_loss'], label='DPA Loss', linewidth=2)\n",
        "    axes[1].plot(history['gmm_loss'], label='GMM Loss', linewidth=2)\n",
        "    axes[1].set_xlabel('Evaluation Step', fontsize=12)\n",
        "    axes[1].set_ylabel('Loss', fontsize=12)\n",
        "    axes[1].set_title('Loss Components', fontsize=14, fontweight='bold')\n",
        "    axes[1].legend(fontsize=10)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    axes[1].set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Extract Latent Representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract latent representations\n",
        "dpa.model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    _, _, z = dpa.model(\n",
        "        x=X.to(dpa.device),\n",
        "        k=dpa.latent_dims[0],\n",
        "        c=E.to(dpa.device),\n",
        "        return_latent=True,\n",
        "        double=True\n",
        "    )\n",
        "    \n",
        "    _, _, z_test = dpa.model(\n",
        "        x=X_test.to(dpa.device),\n",
        "        k=dpa.latent_dims[0],\n",
        "        c=E.to(dpa.device),\n",
        "        return_latent=True,\n",
        "        double=True\n",
        "    )\n",
        "\n",
        "# Center representations based on reference environment\n",
        "n_in_ref = int(torch.sum(E[:, 0]))\n",
        "center_of_z_ref = torch.mean(z[:n_in_ref], dim=0)\n",
        "\n",
        "z_centered = z.cpu() - center_of_z_ref.cpu()\n",
        "z_test_cen = z_test.cpu() - center_of_z_ref.cpu()\n",
        "\n",
        "center_of_y_ref = torch.mean(Y[:n_in_ref])\n",
        "y_centered = Y.cpu() - center_of_y_ref.cpu()\n",
        "y_test_cen = Y_test.cpu() - center_of_y_ref.cpu()\n",
        "\n",
        "print(f\"Latent representations extracted:\")\n",
        "print(f\"  Shape: {z_centered.shape}\")\n",
        "print(f\"  Mean: {z_centered.mean():.4f}\")\n",
        "print(f\"  Std: {z_centered.std():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Apply DRIG and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for DRIG\n",
        "from cirrl.utils.data import prepare_drig_data_from_latents\n",
        "\n",
        "train_data = prepare_drig_data_from_latents(z_centered, y_centered, E)\n",
        "\n",
        "# Test different gamma values\n",
        "gamma_values = np.linspace(0, 15, 16)\n",
        "test_mses = []\n",
        "\n",
        "for gamma in gamma_values:\n",
        "    # Estimate DRIG coefficients\n",
        "    coef = est_drig_gd_auto(\n",
        "        train_data,\n",
        "        gamma=gamma,\n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        verbose=False\n",
        "    )\n",
        "    \n",
        "    # Compute test MSE\n",
        "    y_pred = z_test_cen.numpy() @ coef\n",
        "    mse = np.mean((y_pred.flatten() - y_test_cen.numpy()) ** 2)\n",
        "    test_mses.append(mse)\n",
        "\n",
        "# Find best gamma\n",
        "best_idx = np.argmin(test_mses)\n",
        "best_gamma = gamma_values[best_idx]\n",
        "best_mse = test_mses[best_idx]\n",
        "\n",
        "print(f\"\\nBest gamma: {best_gamma:.2f}\")\n",
        "print(f\"Best test MSE: {best_mse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot MSE vs gamma\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(gamma_values, test_mses, marker='o', linewidth=2, markersize=8)\n",
        "plt.axvline(best_gamma, color='r', linestyle='--', label=f'Best gamma = {best_gamma:.2f}')\n",
        "plt.xlabel('Gamma', fontsize=12)\n",
        "plt.ylabel('Test MSE', fontsize=12)\n",
        "plt.title('Test MSE vs DRIG Gamma Parameter', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compare Different Latent Dimensions (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This will take longer - compares multiple latent dimensions\n",
        "comparison_results = compare_latent_dimensions(\n",
        "    X, Y, E, X_test, Y_test,\n",
        "    latent_dims_list=[2, 3, 5],\n",
        "    seeds=[123, 456],\n",
        "    epochs=500,  # Reduced for demo\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Plot comparison\n",
        "latent_dims = [r['latent_dim'] for r in comparison_results]\n",
        "mean_mses = [np.mean(r['test_mses']) for r in comparison_results]\n",
        "std_mses = [np.std(r['test_mses']) for r in comparison_results]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(latent_dims, mean_mses, yerr=std_mses,\n",
        "             marker='o', capsize=5, capthick=2, linewidth=2)\n",
        "plt.xlabel('Latent Dimension', fontsize=12)\n",
        "plt.ylabel('Test MSE', fontsize=12)\n",
        "plt.title('Performance vs Latent Dimension', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, you learned how to:\n",
        "\n",
        "1. Load single-cell data with multiple environments\n",
        "2. Initialize and train a DPA model for representation learning\n",
        "3. Extract and center latent representations\n",
        "4. Apply DRIG estimator with different gamma values\n",
        "5. Evaluate performance and find optimal hyperparameters\n",
        "6. Compare different latent dimensions\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Try different model architectures (hidden dimensions, number of layers)\n",
        "- Experiment with different training hyperparameters (alpha, beta)\n",
        "- Apply CIRRL to your own datasets\n",
        "- Explore the learned latent representations"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
